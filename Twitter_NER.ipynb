{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "# LSTM components\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "# CRF layer\n",
    "from tensorflow_addons.layers import CRF\n",
    "# Sigmoid focal cross entropy loss. works well with highly unbalanced input data\n",
    "from tensorflow_addons.losses import SigmoidFocalCrossEntropy\n",
    "from tensorflow_addons.optimizers import AdamW\n",
    "from gensim.models import KeyedVectors\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wnut_16_train.txt.conll','r',encoding='utf-8') as f:\n",
    "    raw_train = f.read()\n",
    "\n",
    "with open('wnut_16_test.txt.conll','r',encoding='utf-8') as f:\n",
    "    raw_test = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4850, 1394)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tweets present in train and test\n",
    "len(raw_train.split('\\n\\n')), len(raw_test.split('\\n\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of unique words :  21530\n",
      "\n",
      "Frequency of words: \n",
      " .      2166\n",
      ":      2093\n",
      ",      1803\n",
      "the    1311\n",
      "to     1141\n",
      "Name: 0, dtype: int64\n",
      "----------------------------------------------------------\n",
      "\n",
      "# of unique labels :  21\n",
      "\n",
      "Frequency of labels : \n",
      " O            74245\n",
      "B-geo-loc     1011\n",
      "I-other        713\n",
      "B-company      699\n",
      "B-other        692\n",
      "Name: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# get labels from raw_train\n",
    "train_labels = []\n",
    "train_words = []\n",
    "\n",
    "for tweet in raw_train.split('\\n\\n'):\n",
    "    for line in tweet.split('\\n'):\n",
    "        if line:\n",
    "            train_labels.append(line.split('\\t')[1])\n",
    "            train_words.append(line.split('\\t')[0])\n",
    "\n",
    "print('# of unique words : ', len(set(train_words)))\n",
    "print('\\nFrequency of words: \\n',pd.DataFrame(train_words)[0].value_counts().head())\n",
    "print('-----------------------------'*2)\n",
    "print('\\n# of unique labels : ', len(set(train_labels)))\n",
    "print('\\nFrequency of labels : \\n',pd.DataFrame(train_labels)[0].value_counts().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of unique words :  7203\n",
      "\n",
      "Frequency of words : \n",
      " .      917\n",
      ",      519\n",
      "the    510\n",
      "I      468\n",
      "to     466\n",
      "Name: 0, dtype: int64\n",
      "----------------------------------------------------------\n",
      "\n",
      "# of unique labels :  21\n",
      "\n",
      "Frequency of labels : \n",
      " O            25715\n",
      "B-person       263\n",
      "I-other        163\n",
      "B-geo-loc      147\n",
      "I-person       118\n",
      "Name: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# get labels from raw_test\n",
    "test_labels = []\n",
    "test_words = []\n",
    "\n",
    "for tweet in raw_test.split('\\n\\n'):\n",
    "    for line in tweet.split('\\n'):\n",
    "        if line:\n",
    "            test_labels.append(line.split('\\t')[1])\n",
    "            test_words.append(line.split('\\t')[0])\n",
    "\n",
    "# get unique labels\n",
    "print('# of unique words : ', len(set(test_words)))\n",
    "print('\\nFrequency of words : \\n',pd.DataFrame(test_words)[0].value_counts().head())\n",
    "print('-----------------------------'*2)\n",
    "print('\\n# of unique labels : ', len(set(test_labels)))\n",
    "print('\\nFrequency of labels : \\n',pd.DataFrame(test_labels)[0].value_counts().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sentences(raw):\n",
    "    sentences = []\n",
    "    for tweet in raw.split('\\n\\n'):\n",
    "        sentence = []\n",
    "        for line in tweet.split('\\n'):\n",
    "            if line:\n",
    "                sentence.append(line.split('\\t'))\n",
    "        sentences.append(sentence)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = build_sentences(raw_train)\n",
    "test_sentences = build_sentences(raw_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4850, 1394)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sentences), len(test_sentences) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg length of train sentences : 17.0\n",
      "Max length of train sentences : 37\n",
      "---\n",
      "Avg length of test sentences : 19.0\n",
      "Max length of test sentences : 39\n"
     ]
    }
   ],
   "source": [
    "print('Avg length of train sentences :',np.round(np.mean([len(s) for s in train_sentences])))\n",
    "print('Max length of train sentences :',np.round(np.max([len(s) for s in train_sentences])))\n",
    "print('---')\n",
    "print('Avg length of test sentences :',np.round(np.mean([len(s) for s in test_sentences])))\n",
    "print('Max length of test sentences :',np.round(np.max([len(s) for s in test_sentences])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21530, 21)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_words = len(set(train_words))\n",
    "n_tags = len(set(train_labels))\n",
    "words = list(set(train_words))\n",
    "tags = list(set(train_labels))\n",
    "n_words, n_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary Key:word -> Value:token_index\n",
    "# The first 2 entries are reserved for PAD and UNK\n",
    "word2idx = {w: i + 2 for i, w in enumerate(words)}\n",
    "word2idx[\"PAD\"] = 0 # Padding\n",
    "word2idx[\"UNK\"] = 1 # Unknown words\n",
    "\n",
    "# Vocabulary Key:token_index -> Value:word\n",
    "idx2word = {i: w for w, i in word2idx.items()}\n",
    "\n",
    "# Vocabulary Key:Label/Tag -> Value:tag_index\n",
    "# The first entry is reserved for PAD\n",
    "tag2idx = {t: i+1 for i, t in enumerate(tags)}\n",
    "tag2idx[\"PAD\"] = 0\n",
    "\n",
    "# Vocabulary Key:tag_index -> Value:Label/Tag\n",
    "idx2tag = {i: w for w, i in tag2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word Obama is identified by the index: 15132\n",
      "The labels B-person is identified by the index: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"The word Obama is identified by the index: {}\".format(word2idx[\"Obama\"]))\n",
    "print(\"The labels B-person is identified by the index: {}\".format(tag2idx[\"B-person\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing train test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [[word2idx.get(x[0], word2idx[\"UNK\"]) for x in s] for s in train_sentences]\n",
    "X_train = pad_sequences(maxlen=MAX_LEN, sequences=X_train, padding=\"post\", value = word2idx[\"PAD\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [[word2idx.get(x[0], word2idx[\"UNK\"]) for x in s] for s in test_sentences]\n",
    "X_test = pad_sequences(maxlen=MAX_LEN, sequences=X_test, padding=\"post\", value = word2idx[\"PAD\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = [[tag2idx.get(x[1]) for x in s] for s in train_sentences]\n",
    "y_train = pad_sequences(maxlen=MAX_LEN, sequences=y_train, padding=\"post\", value = tag2idx[\"PAD\"])\n",
    "y_train = np.array([to_categorical(s, num_classes=len(tag2idx)) for s in y_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = [[tag2idx.get(x[1]) for x in s] for s in test_sentences]\n",
    "y_test = pad_sequences(maxlen=MAX_LEN, sequences=y_test, padding=\"post\", value = tag2idx[\"PAD\"])\n",
    "y_test = np.array([to_categorical(s, num_classes=len(tag2idx)) for s in y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4850, 40), (1394, 40), (4850, 40, 22), (1394, 40, 22))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Pretrained Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_w2v = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_w2v['Obama'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words we have embeddings for : 11621 / 21530\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of words we have embeddings for : {len([w for w in set(train_words) if w in pretrained_w2v.key_to_index.keys()])} / {len(set(train_words))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://tinyurl.com/26zeju5',\n",
       " 'http://t.co/6yOqP1HYHV',\n",
       " 'http://t.co/Zrf3iXpjec',\n",
       " 'http://bit.ly/9GkyjU',\n",
       " '(@PaigeLouiseRyan',\n",
       " '#5-8',\n",
       " '@WesternToday',\n",
       " '01:03',\n",
       " '17:00',\n",
       " '@xXLauraJXx']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in set(train_words) if w not in pretrained_w2v.key_to_index.keys()][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_matrix = np.zeros((len(word2idx), 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in word2idx.items():\n",
    "    if k in pretrained_w2v.key_to_index.keys():\n",
    "        embeddings_matrix[v] = pretrained_w2v[k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.random.set_seed(42)\n",
    "tf.random.set_seed(84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(max_len = MAX_LEN, input_dim = len(word2idx), embedding_dim = 100):\n",
    "  \n",
    "  # Model definition\n",
    "  input = Input(shape=(max_len,))\n",
    "\n",
    "  # Get embeddings\n",
    "  embeddings = Embedding(input_dim=input_dim,\n",
    "                      output_dim=embedding_dim,\n",
    "                      input_length=max_len, \n",
    "                      mask_zero=True,\n",
    "                      trainable=True,\n",
    "                      weights=[embeddings_matrix])(input)\n",
    "\n",
    "  # variational biLSTM\n",
    "  output_sequences = Bidirectional(LSTM(units=50, return_sequences=True))(embeddings)\n",
    "\n",
    "  # Stacking\n",
    "  output_sequences = Bidirectional(LSTM(units=50, return_sequences=True))(output_sequences)\n",
    "\n",
    "  # Adding more non-linearity\n",
    "  dense_out = TimeDistributed(Dense(25, activation=\"relu\"))(output_sequences)\n",
    "\n",
    "  # CRF layer\n",
    "  crf = CRF(len(tag2idx), name='crf')\n",
    "  predicted_sequence, potentials, sequence_length, crf_kernel = crf(dense_out)\n",
    "\n",
    "  model = Model(input, potentials)\n",
    "  model.compile(\n",
    "      optimizer=AdamW(weight_decay=0.001),\n",
    "      loss= SigmoidFocalCrossEntropy(alpha=0.125)) # Sigmoid focal cross entropy loss\n",
    "\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 40)]              0         \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 40, 300)           6459600   \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 40, 100)          140400    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 40, 100)          60400     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 40, 25)           2525      \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " crf (CRF)                   [(None, 40),              1100      \n",
      "                              (None, 40, 22),                    \n",
      "                              (None,),                           \n",
      "                              (22, 22)]                          \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,664,025\n",
      "Trainable params: 6,664,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(embedding_dim=300)\n",
    "\n",
    "# Checkpointing\n",
    "save_model = tf.keras.callbacks.ModelCheckpoint(filepath='twitter_ner_crf.h5',\n",
    "  monitor='val_loss',\n",
    "  save_weights_only=True,\n",
    "  save_best_only=True,\n",
    "  verbose=1\n",
    ")\n",
    "\n",
    "# Early stopping\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', verbose=1, patience=10)\n",
    "\n",
    "callbacks = [save_model, es]\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['chain_kernel:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['chain_kernel:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.1999\n",
      "Epoch 1: val_loss improved from inf to 0.09670, saving model to twitter_ner_crf.h5\n",
      "152/152 [==============================] - 66s 289ms/step - loss: 0.1999 - val_loss: 0.0967\n",
      "Epoch 2/10\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.0762\n",
      "Epoch 2: val_loss improved from 0.09670 to 0.05196, saving model to twitter_ner_crf.h5\n",
      "152/152 [==============================] - 34s 222ms/step - loss: 0.0762 - val_loss: 0.0520\n",
      "Epoch 3/10\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.0392\n",
      "Epoch 3: val_loss improved from 0.05196 to 0.04179, saving model to twitter_ner_crf.h5\n",
      "152/152 [==============================] - 34s 220ms/step - loss: 0.0392 - val_loss: 0.0418\n",
      "Epoch 4/10\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.0234\n",
      "Epoch 4: val_loss did not improve from 0.04179\n",
      "152/152 [==============================] - 34s 225ms/step - loss: 0.0234 - val_loss: 0.0550\n",
      "Epoch 5/10\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.0171\n",
      "Epoch 5: val_loss did not improve from 0.04179\n",
      "152/152 [==============================] - 33s 218ms/step - loss: 0.0171 - val_loss: 0.0668\n",
      "Epoch 6/10\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.0140\n",
      "Epoch 6: val_loss did not improve from 0.04179\n",
      "152/152 [==============================] - 33s 218ms/step - loss: 0.0140 - val_loss: 0.0792\n",
      "Epoch 7/10\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.0120\n",
      "Epoch 7: val_loss did not improve from 0.04179\n",
      "152/152 [==============================] - 34s 222ms/step - loss: 0.0120 - val_loss: 0.1244\n",
      "Epoch 8/10\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.0104\n",
      "Epoch 8: val_loss did not improve from 0.04179\n",
      "152/152 [==============================] - 35s 233ms/step - loss: 0.0104 - val_loss: 0.1103\n",
      "Epoch 9/10\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.0091\n",
      "Epoch 9: val_loss did not improve from 0.04179\n",
      "152/152 [==============================] - 33s 214ms/step - loss: 0.0091 - val_loss: 0.1615\n",
      "Epoch 10/10\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.0097\n",
      "Epoch 10: val_loss did not improve from 0.04179\n",
      "152/152 [==============================] - 31s 207ms/step - loss: 0.0097 - val_loss: 0.1447\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bbe901cfd0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 10, shuffle = True, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 10s 35ms/step\n"
     ]
    }
   ],
   "source": [
    "X_test_predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1394, 40, 22)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_predictions = np.argmax(X_test_predictions, axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1394, 40)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_predictions = [[idx2tag.get(x) for x in s] for s in X_test_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Recall :  14.9 %\n",
      "Mean Recall without Others Tag:  11.4 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>actual_tag_count</th>\n",
       "      <th>correctly_predicted_tag_count</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>O</td>\n",
       "      <td>25715</td>\n",
       "      <td>21797</td>\n",
       "      <td>84.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B-geo-loc</td>\n",
       "      <td>147</td>\n",
       "      <td>79</td>\n",
       "      <td>53.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I-other</td>\n",
       "      <td>163</td>\n",
       "      <td>73</td>\n",
       "      <td>44.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>B-other</td>\n",
       "      <td>117</td>\n",
       "      <td>49</td>\n",
       "      <td>41.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>B-company</td>\n",
       "      <td>93</td>\n",
       "      <td>30</td>\n",
       "      <td>32.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>I-facility</td>\n",
       "      <td>60</td>\n",
       "      <td>15</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-person</td>\n",
       "      <td>263</td>\n",
       "      <td>32</td>\n",
       "      <td>12.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I-person</td>\n",
       "      <td>118</td>\n",
       "      <td>13</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>B-facility</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I-product</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B-tvshow</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B-movie</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B-musicartist</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>I-movie</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I-sportsteam</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>B-product</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I-tvshow</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I-geo-loc</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>B-sportsteam</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I-musicartist</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>I-company</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tag  actual_tag_count  correctly_predicted_tag_count  recall\n",
       "17              O             25715                          21797    84.8\n",
       "7       B-geo-loc               147                             79    53.7\n",
       "8         I-other               163                             73    44.8\n",
       "14        B-other               117                             49    41.9\n",
       "19      B-company                93                             30    32.3\n",
       "16     I-facility                60                             15    25.0\n",
       "0        B-person               263                             32    12.2\n",
       "2        I-person               118                             13    11.0\n",
       "12     B-facility                56                              3     5.4\n",
       "10      I-product                43                              1     2.3\n",
       "1        B-tvshow                22                              0     0.0\n",
       "11        B-movie                21                              0     0.0\n",
       "9   B-musicartist                32                              0     0.0\n",
       "13        I-movie                28                              0     0.0\n",
       "6    I-sportsteam                16                              0     0.0\n",
       "15      B-product                60                              0     0.0\n",
       "5        I-tvshow                23                              0     0.0\n",
       "4       I-geo-loc                22                              0     0.0\n",
       "18   B-sportsteam                34                              0     0.0\n",
       "3   I-musicartist                39                              0     0.0\n",
       "20      I-company                15                              0     0.0"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_dict = dict(zip(tags, [[0,0],[0,0],[0,0],[0,0],[0,0],\n",
    "                                   [0,0],[0,0],[0,0],[0,0],[0,0],\n",
    "                                   [0,0],[0,0],[0,0],[0,0],[0,0],\n",
    "                                   [0,0],[0,0],[0,0],[0,0],[0,0],\n",
    "                                   [0,0],[0,0],[0,0],[0,0],[0,0],[0,0]]))\n",
    "for i in range(len(test_sentences)):\n",
    "    for j in range(len(test_sentences[i])):\n",
    "        performance_dict[test_sentences[i][j][1]][0] += 1 # actual tag count\n",
    "        if (test_sentences[i][j][1] == X_test_predictions[i][j]): \n",
    "            performance_dict[test_sentences[i][j][1]][1] += 1\n",
    "performance_dict = pd.DataFrame(performance_dict).T.reset_index()\n",
    "performance_dict.columns = ['tag','actual_tag_count','correctly_predicted_tag_count']\n",
    "performance_dict['recall'] = round(100*performance_dict['correctly_predicted_tag_count']/performance_dict['actual_tag_count'],1)\n",
    "print('Mean Recall : ',performance_dict.loc[:,'recall'].mean().round(1), '%')\n",
    "print('Mean Recall without Others Tag: ',performance_dict.loc[performance_dict['tag']!='O','recall'].mean().round(1), '%')\n",
    "performance_dict.sort_values(by = 'recall', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Not enough training data present for all the tags. Hence, the model is not able to predict all the tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Recall :  14.9 %\n",
      "Mean Recall without Others Tag:  11.4 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>actual_tag_count</th>\n",
       "      <th>correctly_predicted_tag_count</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>O</td>\n",
       "      <td>25715</td>\n",
       "      <td>21797</td>\n",
       "      <td>84.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B-geo-loc</td>\n",
       "      <td>147</td>\n",
       "      <td>79</td>\n",
       "      <td>53.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I-other</td>\n",
       "      <td>163</td>\n",
       "      <td>73</td>\n",
       "      <td>44.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>B-other</td>\n",
       "      <td>117</td>\n",
       "      <td>49</td>\n",
       "      <td>41.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>B-company</td>\n",
       "      <td>93</td>\n",
       "      <td>30</td>\n",
       "      <td>32.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>I-facility</td>\n",
       "      <td>60</td>\n",
       "      <td>15</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-person</td>\n",
       "      <td>263</td>\n",
       "      <td>32</td>\n",
       "      <td>12.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I-person</td>\n",
       "      <td>118</td>\n",
       "      <td>13</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>B-facility</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I-product</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B-tvshow</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B-movie</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B-musicartist</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>I-movie</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I-sportsteam</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>B-product</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I-tvshow</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I-geo-loc</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>B-sportsteam</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I-musicartist</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>I-company</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tag  actual_tag_count  correctly_predicted_tag_count  recall\n",
       "17              O             25715                          21797    84.8\n",
       "7       B-geo-loc               147                             79    53.7\n",
       "8         I-other               163                             73    44.8\n",
       "14        B-other               117                             49    41.9\n",
       "19      B-company                93                             30    32.3\n",
       "16     I-facility                60                             15    25.0\n",
       "0        B-person               263                             32    12.2\n",
       "2        I-person               118                             13    11.0\n",
       "12     B-facility                56                              3     5.4\n",
       "10      I-product                43                              1     2.3\n",
       "1        B-tvshow                22                              0     0.0\n",
       "11        B-movie                21                              0     0.0\n",
       "9   B-musicartist                32                              0     0.0\n",
       "13        I-movie                28                              0     0.0\n",
       "6    I-sportsteam                16                              0     0.0\n",
       "15      B-product                60                              0     0.0\n",
       "5        I-tvshow                23                              0     0.0\n",
       "4       I-geo-loc                22                              0     0.0\n",
       "18   B-sportsteam                34                              0     0.0\n",
       "3   I-musicartist                39                              0     0.0\n",
       "20      I-company                15                              0     0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "performance_dict = dict(zip(tags, [[0,0],[0,0],[0,0],[0,0],[0,0],\n",
    "                                   [0,0],[0,0],[0,0],[0,0],[0,0],\n",
    "                                   [0,0],[0,0],[0,0],[0,0],[0,0],\n",
    "                                   [0,0],[0,0],[0,0],[0,0],[0,0],\n",
    "                                   [0,0],[0,0],[0,0],[0,0],[0,0],[0,0]]))\n",
    "for i in range(len(test_sentences)):\n",
    "    for j in range(len(test_sentences[i])):\n",
    "        performance_dict[test_sentences[i][j][1]][0] += 1 # actual tag count\n",
    "        if (test_sentences[i][j][1] == X_test_predictions[i][j]): \n",
    "            performance_dict[test_sentences[i][j][1]][1] += 1\n",
    "performance_dict = pd.DataFrame(performance_dict).T.reset_index()\n",
    "performance_dict.columns = ['tag','actual_tag_count','correctly_predicted_tag_count']\n",
    "performance_dict['recall'] = round(100*performance_dict['correctly_predicted_tag_count']/performance_dict['actual_tag_count'],1)\n",
    "print('Mean Recall : ',performance_dict.loc[:,'recall'].mean().round(1), '%')\n",
    "print('Mean Recall without Others Tag: ',performance_dict.loc[performance_dict['tag']!='O','recall'].mean().round(1), '%')\n",
    "performance_dict.sort_values(by = 'recall', ascending = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scaler",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
